{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3288731,"sourceType":"datasetVersion","datasetId":1991302}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"%pip install -q evaluate\n%pip install -q opendatasets\n%pip install -q --upgrade accelerate\n%pip install -q --upgrade transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport torch\nimport torchtext\nfrom torch.utils.data import Dataset, random_split\nfrom typing import List, Dict, Union\nfrom typing import Any, TypeVar\nimport pandas as pd\nimport os\nimport copy\nimport gc\nimport evaluate\nimport opendatasets as od\n\nfrom datasets import load_dataset, Features, Value\n\nfrom transformers import AutoTokenizer, Seq2SeqTrainingArguments \nfrom transformers import Seq2SeqTrainer, AutoModelForCausalLM, IntervalStrategy\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:00:51.709590Z","iopub.execute_input":"2024-04-12T17:00:51.709957Z","iopub.status.idle":"2024-04-12T17:00:59.115860Z","shell.execute_reply.started":"2024-04-12T17:00:51.709927Z","shell.execute_reply":"2024-04-12T17:00:59.114967Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-12 17:00:55.521549: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-12 17:00:55.521608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-12 17:00:55.523212: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"set a seed and confirm CUDA support","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(2137)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.backends.cudnn.deterministic = True\n\nprint(\"PyTorch Version: \", torch.__version__)\nprint(\"torchtext Version: \", torchtext.__version__)\nprint(f\"Using {'GPU' if str(DEVICE) == 'cuda' else 'CPU'}.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:01.003284Z","iopub.execute_input":"2024-04-12T17:01:01.003980Z","iopub.status.idle":"2024-04-12T17:01:01.047162Z","shell.execute_reply.started":"2024-04-12T17:01:01.003946Z","shell.execute_reply":"2024-04-12T17:01:01.046223Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"PyTorch Version:  2.1.2\ntorchtext Version:  0.16.2\nUsing GPU.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset Download","metadata":{}},{"cell_type":"markdown","source":"## Downloading MedDialog Dataset","metadata":{}},{"cell_type":"markdown","source":"NOTE: you will need a kaggle API key for the following to work","metadata":{}},{"cell_type":"code","source":"import json\n\n# Path to your JSON file\njson_file_path = \"kaggle.json\"\n\n# Open the file and read the content\ntry:\n  with open(json_file_path, \"r\") as f:\n    json_data = json.load(f)\nexcept FileNotFoundError:\n  print(f\"Error: JSON file not found at {json_file_path}\")\n  exit(1)\n\n# Access username and key from the JSON data\ntry:\n  username = json_data[\"username\"]\n  key = json_data[\"key\"]\nexcept KeyError:\n  print(\"Error: 'username' or 'key' key not found in JSON data\")\n  exit(1)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:04.876116Z","iopub.execute_input":"2024-04-12T17:01:04.878861Z","iopub.status.idle":"2024-04-12T17:01:05.595577Z","shell.execute_reply.started":"2024-04-12T17:01:04.878812Z","shell.execute_reply":"2024-04-12T17:01:05.594126Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Error: JSON file not found at kaggle.json\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Access username and key from the JSON data\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m   username \u001b[38;5;241m=\u001b[39m \u001b[43mjson_data\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m   key \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n","\u001b[0;31mNameError\u001b[0m: name 'json_data' is not defined"],"ename":"NameError","evalue":"name 'json_data' is not defined","output_type":"error"}]},{"cell_type":"code","source":"os.environ['KAGGLE_USERNAME'] = username\nos.environ['KAGGLE_KEY'] = key\n\n# Assign the Kaggle data set URL into variable\ndataset = 'https://www.kaggle.com/datasets/dsxavier/diagnoise-me'\n# Using opendatasets let's download the data sets\nod.download(dataset, \"dataset\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading LiveEQA Dataset","metadata":{}},{"cell_type":"code","source":"liveEQA_dataset = load_dataset(\"truehealth/liveqa\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:09.476049Z","iopub.execute_input":"2024-04-12T17:01:09.476392Z","iopub.status.idle":"2024-04-12T17:01:11.381685Z","shell.execute_reply.started":"2024-04-12T17:01:09.476366Z","shell.execute_reply":"2024-04-12T17:01:11.380734Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(liveEQA_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:12.307399Z","iopub.execute_input":"2024-04-12T17:01:12.308109Z","iopub.status.idle":"2024-04-12T17:01:12.313210Z","shell.execute_reply.started":"2024-04-12T17:01:12.308076Z","shell.execute_reply":"2024-04-12T17:01:12.312340Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'questionid': 'Q1', 'subject': None, 'message': 'Literature on Cardiac amyloidosis.  Please let me know where I can get literature on Cardiac amyloidosis.  My uncle died yesterday from this disorder.  Since this is such a rare disorder, and to honor his memory, I would like to distribute literature at his funeral service.  I am a retired NIH employee, so I am familiar with the campus in case you have literature at NIH that I can come and pick up.  Thank you ', 'focus': 'cardiac amyloidosis', 'type': 'information', 'answerid': 'Q1-S1-A1', 'pairid': '1', 'answer': 'Cardiac amyloidosis is a disorder caused by deposits of an abnormal protein (amyloid) in the heart tissue. These deposits make it hard for the heart to work properly.'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Datasets","metadata":{}},{"cell_type":"markdown","source":"## Loading MedDialog Dataset","metadata":{}},{"cell_type":"code","source":"DATA_PATH = \"dataset\\\\diagnoise-me\\\\diagnose_en_dataset.feather\"\nDATA_PATH = \"/kaggle/input/diagnoise-me/diagnose_en_dataset.feather\"\nSEQ_LEN: int = 1024\ndata = pd.read_feather(DATA_PATH)\nprint(data.keys())\n\n# data = data['Patient'].values\n\n\n# SAMPLE_SIZE: int =  int(data.shape[0] * 0.01) #get 1% of the data\n# _data = [el[:SEQ_LEN]  for el in data[:SAMPLE_SIZE]]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:14.548037Z","iopub.execute_input":"2024-04-12T17:01:14.548412Z","iopub.status.idle":"2024-04-12T17:01:15.314469Z","shell.execute_reply.started":"2024-04-12T17:01:14.548382Z","shell.execute_reply":"2024-04-12T17:01:15.313502Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Index(['id', 'Description', 'Doctor', 'Patient'], dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split data into train and eval sets with 80% for training\ntrain_data, eval_data = train_test_split(data, test_size=0.2, random_state=42)\n\ntrain_data = train_data.reset_index(drop=True)\neval_data = eval_data.reset_index(drop=True)\n\n# Print the shapes of the train and eval sets\nprint(\"Train data shape:\", train_data.shape)\nprint(\"Eval data shape:\", eval_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:16.844371Z","iopub.execute_input":"2024-04-12T17:01:16.845282Z","iopub.status.idle":"2024-04-12T17:01:16.943177Z","shell.execute_reply.started":"2024-04-12T17:01:16.845247Z","shell.execute_reply":"2024-04-12T17:01:16.942191Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Train data shape: (205975, 4)\nEval data shape: (51494, 4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading LiveEQA Dataset","metadata":{}},{"cell_type":"code","source":"liveEQA_dataset = pd.DataFrame({'Doctor': liveEQA_dataset[\"answer\"], 'Patient': liveEQA_dataset[\"message\"]})\n# Print the shapes of the set\nprint(\"LiveEQA data shape:\", liveEQA_dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:20.425959Z","iopub.execute_input":"2024-04-12T17:01:20.426357Z","iopub.status.idle":"2024-04-12T17:01:20.436890Z","shell.execute_reply.started":"2024-04-12T17:01:20.426320Z","shell.execute_reply":"2024-04-12T17:01:20.435882Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"LiveEQA data shape: (635, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create an output directory","metadata":{}},{"cell_type":"code","source":"os.makedirs('./results', exist_ok = True)\nOUTPUT_DIR: str = './results'","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:22.144069Z","iopub.execute_input":"2024-04-12T17:01:22.144704Z","iopub.status.idle":"2024-04-12T17:01:22.149127Z","shell.execute_reply.started":"2024-04-12T17:01:22.144672Z","shell.execute_reply":"2024-04-12T17:01:22.148045Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# tokens for the datset\nMODEL_NAME: str = 'EleutherAI/gpt-neo-125M'\nBOS_TOKEN: str = '<|startoftext|>'\nEOS_TOKEN: str = '<|endoftext|>'\nPAD_TOKEN: str = '<|pad|>'","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:24.735612Z","iopub.execute_input":"2024-04-12T17:01:24.736420Z","iopub.status.idle":"2024-04-12T17:01:24.740931Z","shell.execute_reply.started":"2024-04-12T17:01:24.736383Z","shell.execute_reply":"2024-04-12T17:01:24.739907Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer \nMAX_TOKEN_LENGTH = 1024\n\n# for evaluation\nltokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, bos_token = BOS_TOKEN, eos_token=EOS_TOKEN, pad_token=PAD_TOKEN)\nltokenizer.padding_side = 'left'\nltokenizer.truncation_side = 'left'\n\n# for training\nrtokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, bos_token = BOS_TOKEN, eos_token=EOS_TOKEN, pad_token=PAD_TOKEN)\nrtokenizer.padding_side = 'right'\nrtokenizer.truncation_side = 'right'","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:26.513907Z","iopub.execute_input":"2024-04-12T17:01:26.514276Z","iopub.status.idle":"2024-04-12T17:01:27.108191Z","shell.execute_reply.started":"2024-04-12T17:01:26.514248Z","shell.execute_reply":"2024-04-12T17:01:27.107169Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model =  AutoModelForCausalLM.from_pretrained(MODEL_NAME).cuda()\nmodel.resize_token_embeddings(len(rtokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:29.044808Z","iopub.execute_input":"2024-04-12T17:01:29.045205Z","iopub.status.idle":"2024-04-12T17:01:30.313185Z","shell.execute_reply.started":"2024-04-12T17:01:29.045173Z","shell.execute_reply":"2024-04-12T17:01:30.312194Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Embedding(50259, 768)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preparing Data for Training","metadata":{}},{"cell_type":"markdown","source":"## Custom Dataset","metadata":{}},{"cell_type":"code","source":"class DoctorPatientDataset(Dataset):\n    \n    def __init__(self, data, split):\n        \n        self.input_x: List = data[\"Patient\"]\n        self.target: List = data[\"Doctor\"]\n        self.split = split\n            \n    def __len__(self):\n        return len(self.input_x)\n    \n    def __getitem__(self, idx):\n        data = {\n            'input': self.input_x[idx],\n            'target': self.target[idx],\n            'split': self.split\n        }\n        return data","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:34.571317Z","iopub.execute_input":"2024-04-12T17:01:34.572063Z","iopub.status.idle":"2024-04-12T17:01:34.578183Z","shell.execute_reply.started":"2024-04-12T17:01:34.572032Z","shell.execute_reply":"2024-04-12T17:01:34.577184Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = DoctorPatientDataset(data = train_data, split = \"train\")\neval_dataset_1 = DoctorPatientDataset(data = eval_data, split = \"eval\")\neval_dataset_2 = DoctorPatientDataset(data = liveEQA_dataset, split = \"eval\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:37.374846Z","iopub.execute_input":"2024-04-12T17:01:37.375593Z","iopub.status.idle":"2024-04-12T17:01:37.380634Z","shell.execute_reply.started":"2024-04-12T17:01:37.375555Z","shell.execute_reply":"2024-04-12T17:01:37.379730Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Custom Data Collator","metadata":{}},{"cell_type":"code","source":"def custom_data_collator(features, return_tensors=\"pt\"):\n    batch = {}\n\n    questions = [feature[\"input\"] for feature in features]\n    answers = [feature[\"target\"] for feature in features]\n    split = features[0][\"split\"]\n\n    # training\n    if split == 'train':\n        tokenizer = rtokenizer\n        bos_token = rtokenizer.bos_token\n        eos_token = rtokenizer.eos_token\n        text = [f\"{bos_token}Question:{q}.Answer:{t}{eos_token}\" for q, t in zip(questions, answers)]\n\n    # evaluation\n    else:\n        # Format text to be encoded\n        tokenizer = ltokenizer\n        bos_token = ltokenizer.bos_token\n        text = [f\"{bos_token}Context:{q}.Target:\" for q in questions]\n\n\n    # Tokenize the text\n    encoding = tokenizer(text, truncation=True, padding='max_length', max_length=MAX_TOKEN_LENGTH, return_tensors=return_tensors, add_special_tokens=False)\n\n    # Prepare final batch dictionary\n    batch[\"input_ids\"] = encoding[\"input_ids\"]\n    batch[\"attention_mask\"] = encoding[\"attention_mask\"]\n\n    if return_tensors in [\"pt\", \"tf\"]:\n        batch[\"labels\"] = copy.deepcopy(encoding[\"input_ids\"])\n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:39.027413Z","iopub.execute_input":"2024-04-12T17:01:39.028060Z","iopub.status.idle":"2024-04-12T17:01:39.036278Z","shell.execute_reply.started":"2024-04-12T17:01:39.028030Z","shell.execute_reply":"2024-04-12T17:01:39.035385Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir = OUTPUT_DIR, \n    num_train_epochs = 2, \n    evaluation_strategy=\"steps\",\n    eval_steps = 5000,\n    logging_steps = 5000,\n    save_total_limit = 1,\n    per_device_train_batch_size=2, \n    per_device_eval_batch_size=1, \n    warmup_steps=50, \n    weight_decay=0.01, \n    logging_dir='./logs',\n    save_steps = 0,\n    load_best_model_at_end=True,\n    remove_unused_columns=False,\n    report_to=['tensorboard']\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:42.436983Z","iopub.execute_input":"2024-04-12T17:01:42.437712Z","iopub.status.idle":"2024-04-12T17:01:42.463768Z","shell.execute_reply.started":"2024-04-12T17:01:42.437676Z","shell.execute_reply":"2024-04-12T17:01:42.462964Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model, \n    args=training_args, \n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset_1, \n    data_collator=custom_data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:44.751512Z","iopub.execute_input":"2024-04-12T17:01:44.752201Z","iopub.status.idle":"2024-04-12T17:01:44.773037Z","shell.execute_reply.started":"2024-04-12T17:01:44.752167Z","shell.execute_reply":"2024-04-12T17:01:44.772070Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:01:50.800397Z","iopub.execute_input":"2024-04-12T17:01:50.801166Z","iopub.status.idle":"2024-04-12T17:01:51.095943Z","shell.execute_reply.started":"2024-04-12T17:01:50.801133Z","shell.execute_reply":"2024-04-12T17:01:51.094978Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"323"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:02:14.203305Z","iopub.execute_input":"2024-04-12T17:02:14.204179Z","iopub.status.idle":"2024-04-12T17:04:09.444477Z","shell.execute_reply.started":"2024-04-12T17:02:14.204150Z","shell.execute_reply":"2024-04-12T17:04:09.442997Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='308' max='205976' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   308/205976 01:52 < 21:04:40, 2.71 it/s, Epoch 0.00/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2118\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2121\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2122\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2124\u001b[0m ):\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"trainer.model.save_pretrained(f\"{OUTPUT_DIR}/model_save\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Model","metadata":{}},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(f\"{OUTPUT_DIR}/model_save\")\ntrainer = Seq2SeqTrainer(\n    model=model, \n    args=training_args, \n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset_1, \n    data_collator=custom_data_collator\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"eval_result_1 = trainer.predict(eval_dataset_1, max_new_tokens=MAX_TOKEN_LENGTH)\neval_result_2 = trainer.predict(eval_dataset_2, max_new_tokens=MAX_TOKEN_LENGTH)\nlogits_1 = eval_result_1.predictions\nlogits_1[logits_1 == -100] = ltokenizer.eos_token_id\nlogits_2 = eval_result_2.predictions\nlogits_2[logits_2 == -100] = ltokenizer.eos_token_id","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the raw evaluation output\nraw_text_result_1 = ltokenizer.batch_decode(logits_1, skip_special_tokens=True)\nraw_text_result_2 = ltokenizer.batch_decode(logits_2, skip_special_tokens=True)\n\n# get the questions and ground truths from both evaluation datasets\nquestions_1 = []\nground_truth_1 = []\ntry:\n    for item in eval_dataset_1:\n        questions_1.append(item[\"input\"])\n        ground_truth_1.append(item[\"target\"])\nexcept:\n    pass\n\nquestions_2 = []\nground_truth_2 = []\ntry:\n    for item in eval_dataset_2:\n        questions_2.append(item[\"input\"])\n        ground_truth_2.append(item[\"target\"])\nexcept:\n    pass\n\n# create lists for the text outputs\ntext_result_1 = list()\ntext_result_2 = list()\n\n# get the answers for the MedDialog dataset\nfor item in raw_text_result_1:\n    index = item.find(\"Answer:\")\n    output = item[index+7:]\n    index = output.find(ltokenizer.eos_token)\n    if(index > -1):\n        output = output[:index]\n    text_result_1.append(output)\n\n\n# get the answers for the LiveEQA dataset\nfor item in raw_text_result_2:\n    index = item.find(\"Answer:\")\n    output = item[index+7:]\n    index = output.find(ltokenizer.eos_token)\n    if(index > -1):\n        output = output[:index]\n    text_result_2.append(output)\n\n\n\n# print the first 2 results from each dataset evaluation\nprint(\"============================MedDialog Evaluation============================\")\nfor question, answer in list(zip(questions_1, text_result_1))[:2]:\n    print(f\"\"\"\n    Question: {question}\n    Answer: {answer}\n    \"\"\")\n\nprint(\"============================LiveEQA Evaluation============================\")\nfor question, answer in list(zip(questions_2, text_result_2))[:2]:\n    print(f\"\"\"\n    Question: {question}\n    Answer: {answer}\n    \"\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"# load the evaluation metrics\nbleu_scorer = evaluate.load('bleu')\nrouge_scorer = evaluate.load('rouge')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute the bleu and rouge scores for the MedDialog evaluation\nbleu_score_1 = bleu_scorer.compute(predictions=text_result_1, references=ground_truth_1)\nrouge_score_1 = rouge_scorer.compute(predictions=text_result_1, references=ground_truth_1)\n\n# compute the bleu and rouge scores for the LiveEAQ evaluation\nbleu_score_2 = bleu_scorer.compute(predictions=text_result_1, references=ground_truth_2)\nrouge_score_2 = rouge_scorer.compute(predictions=text_result_1, references=ground_truth_2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print scores for MedDialog evaluation\nprint(\"score on MedDialog Dataset\")\nprint('BLEU1:', bleu_score_1['precisions'][0]*100)\nprint(f\"\"\"\nROUGE-1: {rouge_score_1['rouge1']*100}\nROUGE-2: {rouge_score_1['rouge2']*100}\nROUGE-L: {rouge_score_1['rougeL']*100}\n\"\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print scores for LiveEAQ evaluation\nprint(\"score on LiveEQA Dataset\")\nprint('BLEU1:', bleu_score_2['precisions'][0]*100)\nprint(f\"\"\"\nROUGE-1: {rouge_score_2['rouge1']*100}\nROUGE-2: {rouge_score_2['rouge2']*100}\nROUGE-L: {rouge_score_2['rougeL']*100}\n\"\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree(\"/kaggle/working/logs\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T17:04:14.101587Z","iopub.execute_input":"2024-04-12T17:04:14.101877Z","iopub.status.idle":"2024-04-12T17:04:14.325054Z","shell.execute_reply.started":"2024-04-12T17:04:14.101854Z","shell.execute_reply":"2024-04-12T17:04:14.323941Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/logs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:715\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    713\u001b[0m     orig_st \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlstat(path)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 715\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:713\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# Note: To guard against symlink races, we use the standard\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# lstat()/open()/fstat() trick.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 713\u001b[0m     orig_st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     onerror(os\u001b[38;5;241m.\u001b[39mlstat, path, sys\u001b[38;5;241m.\u001b[39mexc_info())\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/logs'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/logs'","output_type":"error"}]}]}