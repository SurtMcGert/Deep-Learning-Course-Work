{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3288731,"sourceType":"datasetVersion","datasetId":1991302}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"%pip install -q evaluate\n%pip install -q opendatasets\n%pip install -q --upgrade accelerate\n%pip install -q --upgrade transformers\n%pip install -q peft\n%pip install -q --upgrade bitsandbytes\n%pip install -q accelerate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport torch\nimport torch.nn as nn\ntorch.cuda.set_per_process_memory_fraction(0.9)\ntorch.backends.cuda.matmul.allow_tf32 = True\nimport torchtext\nfrom torch.utils.data import Dataset, random_split\nfrom typing import List, Dict, Union\nfrom typing import Any, TypeVar\nimport pandas as pd\nimport os\nimport copy\nimport gc\nimport evaluate\nimport opendatasets as od\nfrom huggingface_hub import login\nfrom typing import Optional, Tuple, Union\n\nfrom datasets import load_dataset, Features, Value\nimport accelerate\n\nfrom peft import LoftQConfig, LoraConfig, get_peft_model, PeftModel\n\nimport transformers\nfrom transformers.modeling_outputs import QuestionAnsweringModelOutput\nfrom transformers import BertLMHeadModel, AutoConfig, BitsAndBytesConfig,Conv1D\nfrom transformers import AutoTokenizer, Seq2SeqTrainingArguments \nfrom transformers import Seq2SeqTrainer, AutoModelForCausalLM, IntervalStrategy, AutoModelForQuestionAnswering\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:48:56.119976Z","iopub.execute_input":"2024-04-19T10:48:56.120678Z","iopub.status.idle":"2024-04-19T10:49:15.291139Z","shell.execute_reply.started":"2024-04-19T10:48:56.120646Z","shell.execute_reply":"2024-04-19T10:49:15.290168Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-19 10:49:04.829195: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-19 10:49:04.829297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-19 10:49:04.965466: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"set a seed and confirm CUDA support","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(2137)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.backends.cudnn.deterministic = True\n\nprint(\"PyTorch Version: \", torch.__version__)\nprint(\"torchtext Version: \", torchtext.__version__)\nprint(f\"Using {'GPU' if str(DEVICE) == 'cuda' else 'CPU'}.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:05:47.777872Z","iopub.execute_input":"2024-04-19T11:05:47.778723Z","iopub.status.idle":"2024-04-19T11:05:47.796626Z","shell.execute_reply.started":"2024-04-19T11:05:47.778688Z","shell.execute_reply":"2024-04-19T11:05:47.795596Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"PyTorch Version:  2.1.2\ntorchtext Version:  0.16.2\nUsing GPU.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset Download","metadata":{}},{"cell_type":"markdown","source":"## Downloading MedDialog Dataset","metadata":{}},{"cell_type":"markdown","source":"NOTE: you will need a kaggle API key for the following to work","metadata":{}},{"cell_type":"code","source":"import json\n\n# Path to your JSON file\njson_file_path = \"kaggle.json\"\n\n# Open the file and read the content\ntry:\n  with open(json_file_path, \"r\") as f:\n    json_data = json.load(f)\nexcept FileNotFoundError:\n  print(f\"Error: JSON file not found at {json_file_path}\")\n  exit(1)\n\n# Access username and key from the JSON data\ntry:\n  username = json_data[\"username\"]\n  key = json_data[\"key\"]\nexcept KeyError:\n  print(\"Error: 'username' or 'key' key not found in JSON data\")\n  exit(1)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:05:50.113954Z","iopub.execute_input":"2024-04-19T11:05:50.114762Z","iopub.status.idle":"2024-04-19T11:05:50.807151Z","shell.execute_reply.started":"2024-04-19T11:05:50.114729Z","shell.execute_reply":"2024-04-19T11:05:50.806067Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Error: JSON file not found at kaggle.json\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Access username and key from the JSON data\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m   username \u001b[38;5;241m=\u001b[39m \u001b[43mjson_data\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m   key \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n","\u001b[0;31mNameError\u001b[0m: name 'json_data' is not defined"],"ename":"NameError","evalue":"name 'json_data' is not defined","output_type":"error"}]},{"cell_type":"code","source":"os.environ['KAGGLE_USERNAME'] = username\nos.environ['KAGGLE_KEY'] = key\n\n# Assign the Kaggle data set URL into variable\ndataset = 'https://www.kaggle.com/datasets/dsxavier/diagnoise-me'\n# Using opendatasets let's download the data sets\nod.download(dataset, \"dataset\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading USMLE Dataset","metadata":{}},{"cell_type":"code","source":"USMLE_dataset = load_dataset(\"GBaker/MedQA-USMLE-4-options\", split=\"test\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:05:53.687857Z","iopub.execute_input":"2024-04-19T11:05:53.688237Z","iopub.status.idle":"2024-04-19T11:06:04.847758Z","shell.execute_reply.started":"2024-04-19T11:05:53.688202Z","shell.execute_reply":"2024-04-19T11:06:04.846862Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0463fd56a4d4ef79ce1384bb7712975"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 16.2M/16.2M [00:03<00:00, 5.05MB/s]\nDownloading data: 100%|██████████| 2.08M/2.08M [00:01<00:00, 1.67MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9998cb04ec466a8d5ff9d77e4d22ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35460528c0594da0a74b4c2fd88f06e5"}},"metadata":{}}]},{"cell_type":"code","source":"print(USMLE_dataset[0])\nprint(len(USMLE_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:06:07.489174Z","iopub.execute_input":"2024-04-19T11:06:07.490073Z","iopub.status.idle":"2024-04-19T11:06:07.499472Z","shell.execute_reply.started":"2024-04-19T11:06:07.490037Z","shell.execute_reply":"2024-04-19T11:06:07.498585Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'question': 'A junior orthopaedic surgery resident is completing a carpal tunnel repair with the department chairman as the attending physician. During the case, the resident inadvertently cuts a flexor tendon. The tendon is repaired without complication. The attending tells the resident that the patient will do fine, and there is no need to report this minor complication that will not harm the patient, as he does not want to make the patient worry unnecessarily. He tells the resident to leave this complication out of the operative report. Which of the following is the correct next action for the resident to take?', 'answer': 'Tell the attending that he cannot fail to disclose this mistake', 'options': {'A': 'Disclose the error to the patient and put it in the operative report', 'B': 'Tell the attending that he cannot fail to disclose this mistake', 'C': 'Report the physician to the ethics committee', 'D': 'Refuse to dictate the operative report'}, 'meta_info': 'step1', 'answer_idx': 'B', 'metamap_phrases': ['junior orthopaedic surgery resident', 'completing', 'carpal tunnel repair', 'department chairman', 'attending physician', 'case', 'resident', 'cuts', 'flexor tendon', 'tendon', 'repaired', 'complication', 'attending', 'resident', 'patient', 'fine', 'need to report', 'minor complication', 'not', 'patient', 'not', 'to make', 'patient worry', 'resident to leave', 'complication out', 'operative report', 'following', 'correct next action', 'resident to take']}\n1273\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Datasets","metadata":{}},{"cell_type":"markdown","source":"## Loading MedDialog Dataset","metadata":{}},{"cell_type":"code","source":"DATA_PATH = \"dataset\\\\diagnoise-me\\\\diagnose_en_dataset.feather\"\nDATA_PATH = \"/kaggle/input/diagnoise-me/diagnose_en_dataset.feather\"\nSEQ_LEN: int = 1024\ndata = pd.read_feather(DATA_PATH)\nSAMPLE_SIZE: int =  int(data.shape[0] * 0.015) #get 1% of the data\ndata = data[:SAMPLE_SIZE]\nprint(data.keys())\nprint(len(data))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:27:53.255089Z","iopub.execute_input":"2024-04-19T11:27:53.255778Z","iopub.status.idle":"2024-04-19T11:27:53.883290Z","shell.execute_reply.started":"2024-04-19T11:27:53.255743Z","shell.execute_reply":"2024-04-19T11:27:53.882362Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Index(['id', 'Description', 'Doctor', 'Patient'], dtype='object')\n3862\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split data into train and eval sets with 70% for training\ntrain_data, eval_data = train_test_split(data, test_size=0.3, random_state=42)\n\ntrain_data = train_data.reset_index(drop=True)\neval_data = eval_data.reset_index(drop=True)\n\n# Print the shapes of the train and eval sets\nprint(\"Train data shape:\", train_data.shape)\nprint(\"Eval data shape:\", eval_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:27:56.259775Z","iopub.execute_input":"2024-04-19T11:27:56.260129Z","iopub.status.idle":"2024-04-19T11:27:56.270232Z","shell.execute_reply.started":"2024-04-19T11:27:56.260099Z","shell.execute_reply":"2024-04-19T11:27:56.269285Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Train data shape: (2703, 4)\nEval data shape: (1159, 4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading USMLE Dataset","metadata":{}},{"cell_type":"code","source":"USMLE_dataset = pd.DataFrame({'Doctor': USMLE_dataset[\"answer\"], 'Patient': USMLE_dataset[\"question\"], 'Options':USMLE_dataset[\"options\"]})\n# Print the shapes of the set\nprint(\"USMLELiveEQA data shape:\", USMLE_dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:07:40.185631Z","iopub.execute_input":"2024-04-19T11:07:40.185989Z","iopub.status.idle":"2024-04-19T11:07:40.214322Z","shell.execute_reply.started":"2024-04-19T11:07:40.185957Z","shell.execute_reply":"2024-04-19T11:07:40.213458Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"USMLELiveEQA data shape: (1273, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create an output directory","metadata":{}},{"cell_type":"code","source":"os.makedirs('./results', exist_ok = True)\nOUTPUT_DIR: str = './results'","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:07:50.920944Z","iopub.execute_input":"2024-04-19T11:07:50.921288Z","iopub.status.idle":"2024-04-19T11:07:50.926377Z","shell.execute_reply.started":"2024-04-19T11:07:50.921261Z","shell.execute_reply":"2024-04-19T11:07:50.925315Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# tokens for the datset\nMODEL_NAME: str = 'UnfilteredAI/Mia-1B'","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:07:53.894720Z","iopub.execute_input":"2024-04-19T11:07:53.895524Z","iopub.status.idle":"2024-04-19T11:07:53.899697Z","shell.execute_reply.started":"2024-04-19T11:07:53.895483Z","shell.execute_reply":"2024-04-19T11:07:53.898798Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer \nMAX_TOKEN_LENGTH = 1024\n\n# for evaluation\nltokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nltokenizer.padding_side = 'left'\nltokenizer.truncation_side = 'left'\n\n# for training\nrtokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nrtokenizer.padding_side = 'right'\nrtokenizer.truncation_side = 'right'","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:07:55.964151Z","iopub.execute_input":"2024-04-19T11:07:55.964599Z","iopub.status.idle":"2024-04-19T11:08:01.241171Z","shell.execute_reply.started":"2024-04-19T11:07:55.964562Z","shell.execute_reply":"2024-04-19T11:08:01.240330Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"101f435cc0be464082319b42b17978f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"276afa3b166e452b8ab781a87a088353"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80243324b4e84ca6af04088ba2c30145"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04f9e52e4c104a6e82b62fec1d2ea220"}},"metadata":{}}]},{"cell_type":"code","source":"base_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n#base_model.resize_token_embeddings(len(rtokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:08:03.793345Z","iopub.execute_input":"2024-04-19T11:08:03.794083Z","iopub.status.idle":"2024-04-19T11:09:33.534605Z","shell.execute_reply.started":"2024-04-19T11:08:03.794050Z","shell.execute_reply":"2024-04-19T11:09:33.533690Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb56140d83e4f1bb709ebf65ed74f1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"234063918b0d48ab9c50299102e879c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/145 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c2c53674c4f486dafa8423815149148"}},"metadata":{}}]},{"cell_type":"code","source":"print(base_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:23:03.196111Z","iopub.execute_input":"2024-04-19T11:23:03.197046Z","iopub.status.idle":"2024-04-19T11:23:03.203694Z","shell.execute_reply.started":"2024-04-19T11:23:03.197010Z","shell.execute_reply":"2024-04-19T11:23:03.202724Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32000, 2048)\n    (layers): ModuleList(\n      (0-21): 22 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"lora_config = LoraConfig(\n    lora_alpha=16, # lora alpha for scaling\n    r=16, # rank\n    lora_dropout=0.05, #dropout\n    use_rslora=True, #  sets the adapter scaling factor to lora_alpha/math.sqrt(r)\n    bias=\"none\", # dont train biases\n    target_modules=[\"q_proj\", \"v_proj\"],\n    #layers_to_transform=[20]\n)\nmodel = get_peft_model(base_model, lora_config)\nmodel.gradient_checkpointing_enable()\nmodel.enable_input_require_grads()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:23:05.504721Z","iopub.execute_input":"2024-04-19T11:23:05.505086Z","iopub.status.idle":"2024-04-19T11:23:05.616160Z","shell.execute_reply.started":"2024-04-19T11:23:05.505055Z","shell.execute_reply":"2024-04-19T11:23:05.615419Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\n    return {\"trainable\": trainable_params, \"all\": all_param, \"trainable%\": 100 * trainable_params / all_param}\n\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:23:08.486718Z","iopub.execute_input":"2024-04-19T11:23:08.487577Z","iopub.status.idle":"2024-04-19T11:23:08.502153Z","shell.execute_reply.started":"2024-04-19T11:23:08.487525Z","shell.execute_reply":"2024-04-19T11:23:08.501333Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"trainable params: 2252800 || all params: 1102301184 || trainable%: 0.20437245579516677\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'trainable': 2252800, 'all': 1102301184, 'trainable%': 0.20437245579516677}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preparing Data for Training","metadata":{}},{"cell_type":"markdown","source":"## Custom Dataset","metadata":{}},{"cell_type":"code","source":"class DoctorPatientDataset(Dataset):\n    \n    def __init__(self, data, split):\n        \n        self.input_x: List = data[\"Patient\"]\n        self.target: List = data[\"Doctor\"]\n        self.split = split\n\n        try:\n            self.options: List = data[\"Options\"]\n        except:\n            pass\n            \n    def __len__(self):\n        return len(self.input_x)\n    \n    def __getitem__(self, idx):\n        try:\n            data = {\n                'input': self.input_x[idx],\n                'target': self.target[idx],\n                'options': self.options[idx],\n                'split': self.split\n            }\n        except:\n            data = {\n                'input': self.input_x[idx],\n                'target': self.target[idx],\n                'split': self.split\n            }\n        return data","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:23:12.099071Z","iopub.execute_input":"2024-04-19T11:23:12.099674Z","iopub.status.idle":"2024-04-19T11:23:12.106883Z","shell.execute_reply.started":"2024-04-19T11:23:12.099642Z","shell.execute_reply":"2024-04-19T11:23:12.106003Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_dataset = DoctorPatientDataset(data = train_data, split = \"train\")\neval_dataset_1 = DoctorPatientDataset(data = eval_data, split = \"eval\")\neval_dataset_2 = DoctorPatientDataset(data = USMLE_dataset, split = \"eval\")\n\ntest_dataset = DoctorPatientDataset(data = eval_data[0:1], split = \"eval\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:58:28.726756Z","iopub.execute_input":"2024-04-19T13:58:28.727144Z","iopub.status.idle":"2024-04-19T13:58:28.733197Z","shell.execute_reply.started":"2024-04-19T13:58:28.727114Z","shell.execute_reply":"2024-04-19T13:58:28.732239Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"## Custom Data Collator","metadata":{}},{"cell_type":"code","source":"def format_text(message, tokenizer):\n    text = tokenizer.apply_chat_template(\n        message,\n        tokenize=False,\n        add_generation_prompt=False\n    )\n    return text\n\ndef custom_data_collator(features, return_tensors=\"pt\"):\n    batch = {}\n\n    questions = [feature[\"input\"] for feature in features]\n    answers = [feature[\"target\"] for feature in features]\n    split = features[0][\"split\"]\n\n    # training\n    if split == 'train':\n        tokenizer = rtokenizer\n        bos_token = rtokenizer.bos_token\n        eos_token = rtokenizer.eos_token\n        prompts = [f\"a medical student is preparing for her final examination. Her patient has said '{q}'. Explain to the student the most likely cause/course of action.\" for q in questions]\n        #text = [f\"{bos_token}Question:{q}.Answer:{t}{eos_token}\" for q, t in zip(questions, answers)]\n        messages = [[\n            {\"role\": \"system\", \"content\": \"You are a medical professional providing consultation and medical diagnostics.\"},\n            {\"role\": \"user\", \"content\": prompt},\n            {\"role\": \"assistant\", \"content\": a}\n        ] for prompt, a in zip(prompts, answers)]\n\n    # evaluation\n    else:\n        try:\n            options = [feature[\"options\"] for feature in features]\n            multi_choice = True\n        except:\n            multi_choice = False\n\n\n        # tokenizer for evaluation\n        tokenizer = ltokenizer\n        bos_token = ltokenizer.bos_token\n\n        # Format text to be encoded\n        if(multi_choice == False):\n            # if we are not using the multiple choice dataset\n            # text = [f\"{bos_token}Question:{q}.Answer:\" for q in questions]\n            prompts = [f\"a medical student is preparing for her final examination. Her patient has said '{q}'. Explain to the student the most likely cause/course of action.\" for q in questions]\n            messages = [[\n                {\"role\": \"system\", \"content\": \"You are a medical professional providing consultation and medical diagnostics.\"},\n                {\"role\": \"user\", \"content\": prompt},\n                {\"role\": \"assistant\", \"content\":\"\"}\n            ] for prompt in prompts]\n        else:\n            # if we are using the multiple choice dataset\n            # prompts = [f\"provided the following text about medical symptoms: '{q}' Please state the most likely cause/course of action from the options below: A: {o['A']} B: {o['B']} C: {o['C']} D: {o['D']} Please select your answer with the format shown in the following example:'The correct option is C'\" for q, o in zip(questions, options)]\n            # text = [f\"{bos_token}Question:{p}.Answer:\" for p in prompts]\n            prompts = [f\"a medical student is preparing for her final examination. Her patient has said '{q}'. Please clearly state a cause/course of action from the provided options:  A: {o['A']} B: {o['B']} C: {o['C']} D: {o['D']} and explain your answer\" for q, o in zip(questions, options)]\n            messages = [[\n                {\"role\": \"system\", \"content\": \"You are a medical professional providing consultation and medical diagnostics.\"},\n                {\"role\": \"user\", \"content\": prompt},\n                {\"role\": \"assistant\", \"content\":\"\"}\n            ] for prompt in prompts]\n\n\n    # Tokenize the text\n    text = list(map(lambda x: format_text(x, tokenizer), messages))\n    \n    encoding = tokenizer(text, truncation=True, padding='max_length', max_length=MAX_TOKEN_LENGTH, return_tensors=return_tensors, add_special_tokens=False)\n    # encoding = tokenizer(text, truncation=True, padding='max_length', max_length=512, return_tensors=return_tensors, add_special_tokens=False)\n\n    # Prepare final batch dictionary\n    batch[\"input_ids\"] = encoding[\"input_ids\"]\n    batch[\"attention_mask\"] = encoding[\"attention_mask\"]\n\n    if return_tensors in [\"pt\", \"tf\"]:\n        batch[\"labels\"] = copy.deepcopy(encoding[\"input_ids\"])\n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:28:18.723313Z","iopub.execute_input":"2024-04-19T11:28:18.723782Z","iopub.status.idle":"2024-04-19T11:28:18.738626Z","shell.execute_reply.started":"2024-04-19T11:28:18.723749Z","shell.execute_reply":"2024-04-19T11:28:18.737643Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir = OUTPUT_DIR, \n    num_train_epochs = 1, \n    evaluation_strategy=\"steps\",\n    #eval_steps = 50,\n    #logging_steps = 50,\n    save_total_limit = 1,\n    per_device_train_batch_size=8, \n    per_device_eval_batch_size=1,\n    bf16=False,\n    fp16=True,\n    warmup_steps=0, \n    weight_decay=0.01, \n    logging_dir='./logs',\n    save_steps = 0,\n    load_best_model_at_end=True,\n    remove_unused_columns=False,\n#     generation_config=transformers.GenerationConfig(\n#             max_length=2048,\n#             num_beams=10,\n#     ),\n    predict_with_generate=True,\n    # prediction_loss_only=True,\n    eval_accumulation_steps=10,\n    report_to=['tensorboard']\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:02:19.863596Z","iopub.execute_input":"2024-04-19T15:02:19.864293Z","iopub.status.idle":"2024-04-19T15:02:19.890708Z","shell.execute_reply.started":"2024-04-19T15:02:19.864260Z","shell.execute_reply":"2024-04-19T15:02:19.890003Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model, \n    args=training_args, \n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset_1, \n    data_collator=custom_data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:28:31.159139Z","iopub.execute_input":"2024-04-19T11:28:31.159856Z","iopub.status.idle":"2024-04-19T11:28:31.178991Z","shell.execute_reply.started":"2024-04-19T11:28:31.159822Z","shell.execute_reply":"2024-04-19T11:28:31.178078Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"trainer = None\nmodel = None\nbase_model = None\ntrain_dataset = None\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:02:21.257868Z","iopub.execute_input":"2024-04-19T15:02:21.258234Z","iopub.status.idle":"2024-04-19T15:02:22.187750Z","shell.execute_reply.started":"2024-04-19T15:02:21.258203Z","shell.execute_reply":"2024-04-19T15:02:22.186770Z"},"trusted":true},"execution_count":180,"outputs":[{"execution_count":180,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:28:40.050420Z","iopub.execute_input":"2024-04-19T11:28:40.050788Z","iopub.status.idle":"2024-04-19T12:20:29.751813Z","shell.execute_reply.started":"2024-04-19T11:28:40.050757Z","shell.execute_reply":"2024-04-19T12:20:29.751036Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='338' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [338/338 51:40, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=338, training_loss=0.8510009946202385, metrics={'train_runtime': 3109.3435, 'train_samples_per_second': 0.869, 'train_steps_per_second': 0.109, 'total_flos': 1.7217799940210688e+16, 'train_loss': 0.8510009946202385, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.model.save_pretrained(f\"{OUTPUT_DIR}/model_save\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T12:22:56.057267Z","iopub.execute_input":"2024-04-19T12:22:56.057701Z","iopub.status.idle":"2024-04-19T12:22:57.137497Z","shell.execute_reply.started":"2024-04-19T12:22:56.057664Z","shell.execute_reply":"2024-04-19T12:22:57.136405Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# Load the Model","metadata":{}},{"cell_type":"code","source":"base_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\nbase_model.resize_token_embeddings(len(rtokenizer))\nmodel = PeftModel.from_pretrained(base_model, f\"{OUTPUT_DIR}/model_save\")\nmodel.config.pad_token_id = ltokenizer.pad_token_id\nmodel.gradient_checkpointing_enable()\nmodel.enable_input_require_grads()\ntrainer = Seq2SeqTrainer(\n    model=model, \n    args=training_args, \n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset_1, \n    data_collator=custom_data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:02:23.460110Z","iopub.execute_input":"2024-04-19T15:02:23.461043Z","iopub.status.idle":"2024-04-19T15:02:26.752107Z","shell.execute_reply.started":"2024-04-19T15:02:23.461007Z","shell.execute_reply":"2024-04-19T15:02:26.751234Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"base_model = None\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:48:33.451490Z","iopub.execute_input":"2024-04-19T14:48:33.451933Z","iopub.status.idle":"2024-04-19T14:48:33.961028Z","shell.execute_reply.started":"2024-04-19T14:48:33.451903Z","shell.execute_reply":"2024-04-19T14:48:33.960080Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"eval_result_1 = trainer.predict(eval_dataset_1, max_new_tokens=512)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T12:24:57.929296Z","iopub.execute_input":"2024-04-19T12:24:57.929823Z","iopub.status.idle":"2024-04-19T12:46:16.779929Z","shell.execute_reply.started":"2024-04-19T12:24:57.929788Z","shell.execute_reply":"2024-04-19T12:46:16.778942Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"eval_result_2 = trainer.predict(eval_dataset_2, max_new_tokens=512)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:03:13.106466Z","iopub.execute_input":"2024-04-19T13:03:13.107431Z","iopub.status.idle":"2024-04-19T13:27:00.815684Z","shell.execute_reply.started":"2024-04-19T13:03:13.107395Z","shell.execute_reply":"2024-04-19T13:27:00.814730Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"logits_1 = eval_result_1.predictions\nlogits_1[logits_1 == -100] = ltokenizer.eos_token_id\nlogits_2 = eval_result_2.predictions\nlogits_2[logits_2 == -100] = ltokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:55:28.108341Z","iopub.execute_input":"2024-04-19T13:55:28.109237Z","iopub.status.idle":"2024-04-19T13:55:28.117415Z","shell.execute_reply.started":"2024-04-19T13:55:28.109201Z","shell.execute_reply":"2024-04-19T13:55:28.116480Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# get the raw evaluation output\nraw_text_result_1 = ltokenizer.batch_decode(logits_1, skip_special_tokens=True)\nraw_text_result_2 = ltokenizer.batch_decode(logits_2, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:35:24.773414Z","iopub.execute_input":"2024-04-19T14:35:24.774331Z","iopub.status.idle":"2024-04-19T14:35:25.820879Z","shell.execute_reply.started":"2024-04-19T14:35:24.774293Z","shell.execute_reply":"2024-04-19T14:35:25.820059Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"print(raw_text_result_1[6])","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:35:32.539810Z","iopub.execute_input":"2024-04-19T14:35:32.540613Z","iopub.status.idle":"2024-04-19T14:35:32.545676Z","shell.execute_reply.started":"2024-04-19T14:35:32.540574Z","shell.execute_reply":"2024-04-19T14:35:32.544603Z"},"trusted":true},"execution_count":132,"outputs":[{"name":"stdout","text":"<|system|>You are a medical professional providing consultation and medical diagnostics. <|user|>a medical student is preparing for her final examination. Her patient has said 'Hello doctor,  I had a staph infection and I took antibiotics a month ago. I had been in the sun a lot recently and I am feeling symptoms of heat exhaustion, but I am worried that the staph infection is causing septic shock? Is this a possibility?'. Explain to the student the most likely cause/course of action. <|assistant|>\n","output_type":"stream"}]},{"cell_type":"code","source":"# get the questions and ground truths from both evaluation datasets\nquestions_1 = []\nground_truth_1 = []\ntry:\n    for item in eval_dataset_1:\n        questions_1.append(item[\"input\"])\n        ground_truth_1.append(item[\"target\"])\nexcept:\n    pass\n\nquestions_2 = []\nground_truth_2 = []\ntry:\n    for item in eval_dataset_2:\n        questions_2.append(item[\"input\"])\n        ground_truth_2.append(item[\"target\"])\nexcept:\n    pass\n\n# create lists for the text outputs\ntext_result_1 = list()\ntext_result_2 = list()\n\n# get the answers for the MedDialog dataset\nfor item in raw_text_result_1:\n    index = item.find(\"|<assistant>|\")\n    output = item[index+13:]\n    index = output.find(ltokenizer.eos_token)\n    if(index > -1):\n        output = output[:index]\n    text_result_1.append(output)\n\n\n# get the answers for the USMLE dataset\nfor item in raw_text_result_2:\n    index = item.find(\"|<assistant>|\")\n    output = item[index+13:]\n    index = output.find(ltokenizer.eos_token)\n    if(index > -1):\n        output = output[:index]\n    text_result_2.append(output)\n\n\n\n# print the first 2 results from each dataset evaluation\nprint(\"============================MedDialog Evaluation============================\")\nfor question, answer in list(zip(questions_1, text_result_1))[:2]:\n    print(f\"\"\"\n    Question: {question}\n    Answer: {answer}\n    \"\"\")\n\nprint(\"============================USMLE Evaluation============================\")\nfor question, answer in list(zip(questions_2, text_result_2))[:2]:\n    print(f\"\"\"\n    Question: {question}\n    Answer: {answer}\n    \"\"\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:55:30.177686Z","iopub.execute_input":"2024-04-19T13:55:30.178036Z","iopub.status.idle":"2024-04-19T13:55:31.257089Z","shell.execute_reply.started":"2024-04-19T13:55:30.178010Z","shell.execute_reply":"2024-04-19T13:55:31.256115Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"<|system|>You are a medical professional providing consultation and medical diagnostics. <|user|>a medical student is preparing for her final examination. Her patient has said 'Hi doctor, I am a 15 year old boy and I have hyperhidrosis. I sweat so much. My shirt cannot stay on for at least 5 minutes. In some half an hour to one hour my whole shirt and armpit area will drench in sweat. Yes, I take a shower twice a day and put deodorant every day. I have even tried the antiperspirant deodorant, but that did not stop it and I think it made it worse. I really want to believe it is just puberty as this has been going on since I was 12 or 13. But, something tells me that it is not because of puberty. Everyone else at school does not have this problem and some relatives in my family has it too. Just like my shirt, my pants will start soaking after 30 minutes of sitting down. I really want a diagnosis or close to one before I actually go to a doctor as I have not yet regarding my issue. Also are there any home remedies or other over-the-counter deodorant to help minimize this issue or completely stop it? I am really fit and regularly lift weights, play lots of sports (soccer, boxing, etc.,) and keep my body in good shape. I know that weight lifting could not be a problem if that was a suggestion. I sweat a lot when I am in social places such as school or when I go out. It is not because of anxiety, but I rarely feel nervous when my arms are getting drenched. This is a more serious problem in the morning either at home or at a social place and gradually calms during the afternoon when I am at home. It is so bad that my armpits can drench two layers of clothing. For example, if I wear a shirt and a jacket over it, then it does not really matter how many layers and by the end of the day my clothing will be soaked in sweat. I do not really have any symptoms besides the fact that I am always on alert when I am out. This is really embarrassing and I have no idea what to do about this. Please help.'. Explain to the student the most likely cause/course of action. <|assistant|>\n============================MedDialog Evaluation============================\n\n    Question: Hi doctor, I am a 15 year old boy and I have hyperhidrosis. I sweat so much. My shirt cannot stay on for at least 5 minutes. In some half an hour to one hour my whole shirt and armpit area will drench in sweat. Yes, I take a shower twice a day and put deodorant every day. I have even tried the antiperspirant deodorant, but that did not stop it and I think it made it worse. I really want to believe it is just puberty as this has been going on since I was 12 or 13. But, something tells me that it is not because of puberty. Everyone else at school does not have this problem and some relatives in my family has it too. Just like my shirt, my pants will start soaking after 30 minutes of sitting down. I really want a diagnosis or close to one before I actually go to a doctor as I have not yet regarding my issue. Also are there any home remedies or other over-the-counter deodorant to help minimize this issue or completely stop it? I am really fit and regularly lift weights, play lots of sports (soccer, boxing, etc.,) and keep my body in good shape. I know that weight lifting could not be a problem if that was a suggestion. I sweat a lot when I am in social places such as school or when I go out. It is not because of anxiety, but I rarely feel nervous when my arms are getting drenched. This is a more serious problem in the morning either at home or at a social place and gradually calms during the afternoon when I am at home. It is so bad that my armpits can drench two layers of clothing. For example, if I wear a shirt and a jacket over it, then it does not really matter how many layers and by the end of the day my clothing will be soaked in sweat. I do not really have any symptoms besides the fact that I am always on alert when I am out. This is really embarrassing and I have no idea what to do about this. Please help.\n    Answer: u are a medical professional providing consultation and medical diagnostics. <|user|>a medical student is preparing for her final examination. Her patient has said 'Hi doctor, I am a 15 year old boy and I have hyperhidrosis. I sweat so much. My shirt cannot stay on for at least 5 minutes. In some half an hour to one hour my whole shirt and armpit area will drench in sweat. Yes, I take a shower twice a day and put deodorant every day. I have even tried the antiperspirant deodorant, but that did not stop it and I think it made it worse. I really want to believe it is just puberty as this has been going on since I was 12 or 13. But, something tells me that it is not because of puberty. Everyone else at school does not have this problem and some relatives in my family has it too. Just like my shirt, my pants will start soaking after 30 minutes of sitting down. I really want a diagnosis or close to one before I actually go to a doctor as I have not yet regarding my issue. Also are there any home remedies or other over-the-counter deodorant to help minimize this issue or completely stop it? I am really fit and regularly lift weights, play lots of sports (soccer, boxing, etc.,) and keep my body in good shape. I know that weight lifting could not be a problem if that was a suggestion. I sweat a lot when I am in social places such as school or when I go out. It is not because of anxiety, but I rarely feel nervous when my arms are getting drenched. This is a more serious problem in the morning either at home or at a social place and gradually calms during the afternoon when I am at home. It is so bad that my armpits can drench two layers of clothing. For example, if I wear a shirt and a jacket over it, then it does not really matter how many layers and by the end of the day my clothing will be soaked in sweat. I do not really have any symptoms besides the fact that I am always on alert when I am out. This is really embarrassing and I have no idea what to do about this. Please help.'. Explain to the student the most likely cause/course of action. <|assistant|>\n    \n\n    Question: Hello doctor, My wife is 5 months pregnant. She is treated in one of the reputed hospitals. She has been advised to take Feronia -XT and Cal 360 tablets. Over last three to four days she is having cough in the night time and she is afraid to use any tablets or tonic. Kindly suggest which tablet or tonic she should take.\n    Answer: u are a medical professional providing consultation and medical diagnostics. <|user|>a medical student is preparing for her final examination. Her patient has said 'Hello doctor, My wife is 5 months pregnant. She is treated in one of the reputed hospitals. She has been advised to take Feronia -XT and Cal 360 tablets. Over last three to four days she is having cough in the night time and she is afraid to use any tablets or tonic. Kindly suggest which tablet or tonic she should take.'. Explain to the student the most likely cause/course of action. <|assistant|>\n    \n============================USMLE Evaluation============================\n\n    Question: A junior orthopaedic surgery resident is completing a carpal tunnel repair with the department chairman as the attending physician. During the case, the resident inadvertently cuts a flexor tendon. The tendon is repaired without complication. The attending tells the resident that the patient will do fine, and there is no need to report this minor complication that will not harm the patient, as he does not want to make the patient worry unnecessarily. He tells the resident to leave this complication out of the operative report. Which of the following is the correct next action for the resident to take?\n    Answer: u are a medical professional providing consultation and medical diagnostics. <|user|>a medical student is preparing for her final examination. Her patient has said 'A junior orthopaedic surgery resident is completing a carpal tunnel repair with the department chairman as the attending physician. During the case, the resident inadvertently cuts a flexor tendon. The tendon is repaired without complication. The attending tells the resident that the patient will do fine, and there is no need to report this minor complication that will not harm the patient, as he does not want to make the patient worry unnecessarily. He tells the resident to leave this complication out of the operative report. Which of the following is the correct next action for the resident to take?'. Please clearly state a cause/course of action from the provided options:  A: Disclose the error to the patient and put it in the operative report B: Tell the attending that he cannot fail to disclose this mistake C: Report the physician to the ethics committee D: Refuse to dictate the operative report and explain your answer <|assistant|>\n    \n\n    Question: A 67-year-old man with transitional cell carcinoma of the bladder comes to the physician because of a 2-day history of ringing sensation in his ear. He received this first course of neoadjuvant chemotherapy 1 week ago. Pure tone audiometry shows a sensorineural hearing loss of 45 dB. The expected beneficial effect of the drug that caused this patient's symptoms is most likely due to which of the following actions?\n    Answer: u are a medical professional providing consultation and medical diagnostics. <|user|>a medical student is preparing for her final examination. Her patient has said 'A 67-year-old man with transitional cell carcinoma of the bladder comes to the physician because of a 2-day history of ringing sensation in his ear. He received this first course of neoadjuvant chemotherapy 1 week ago. Pure tone audiometry shows a sensorineural hearing loss of 45 dB. The expected beneficial effect of the drug that caused this patient's symptoms is most likely due to which of the following actions?'. Please clearly state a cause/course of action from the provided options:  A: Inhibition of proteasome B: Hyperstabilization of microtubules C: Generation of free radicals D: Cross-linking of DNA and explain your answer <|assistant|>\n    \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"markdown","source":"## Load the Required Evaluation Metrics","metadata":{}},{"cell_type":"code","source":"# perplexity - measures certainty of the model.\n# METEOR - extension of BLEU (measure similarity between the output and the ground truth) but accounts for word semantics.\n# ROUGE - considers n-gram overlap (recall) but also precision.\n# SQuAD v2 - a metric for measuring a models correctness in answering the multiple choice questions\n# Accuracy - use this for the multiple choice dataset\n\nperplexity_scorer = evaluate.load('perplexity')\nmeteor_scorer = evaluate.load('meteor')\nrouge_scorer = evaluate.load('rouge')\nsquad_scorer = evaluate.load('squad_v2')\naccuracy_scorer = evaluate.load('accuracy')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute the bleu and rouge scores for the MedDialog evaluation\nbleu_score_1 = bleu_scorer.compute(predictions=text_result_1, references=ground_truth_1)\nrouge_score_1 = rouge_scorer.compute(predictions=text_result_1, references=ground_truth_1)\n\n# compute the bleu and rouge scores for the USMLE evaluation\nbleu_score_2 = bleu_scorer.compute(predictions=text_result_1, references=ground_truth_2)\nrouge_score_2 = rouge_scorer.compute(predictions=text_result_1, references=ground_truth_2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print scores for MedDialog evaluation\nprint(\"score on MedDialog Dataset\")\nprint('BLEU1:', bleu_score_1['precisions'][0]*100)\nprint(f\"\"\"\nROUGE-1: {rouge_score_1['rouge1']*100}\nROUGE-2: {rouge_score_1['rouge2']*100}\nROUGE-L: {rouge_score_1['rougeL']*100}\n\"\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print scores for USMLE evaluation\nprint(\"score on USMLE Dataset\")\nprint('BLEU1:', bleu_score_2['precisions'][0]*100)\nprint(f\"\"\"\nROUGE-1: {rouge_score_2['rouge1']*100}\nROUGE-2: {rouge_score_2['rouge2']*100}\nROUGE-L: {rouge_score_2['rougeL']*100}\n\"\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree(\"/kaggle/working/logs\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.config)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:47:56.698925Z","iopub.execute_input":"2024-04-19T14:47:56.699280Z","iopub.status.idle":"2024-04-19T14:47:56.704238Z","shell.execute_reply.started":"2024-04-19T14:47:56.699252Z","shell.execute_reply":"2024-04-19T14:47:56.703311Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"{'input': 'Hi doctor, I am a 15 year old boy and I have hyperhidrosis. I sweat so much. My shirt cannot stay on for at least 5 minutes. In some half an hour to one hour my whole shirt and armpit area will drench in sweat. Yes, I take a shower twice a day and put deodorant every day. I have even tried the antiperspirant deodorant, but that did not stop it and I think it made it worse. I really want to believe it is just puberty as this has been going on since I was 12 or 13. But, something tells me that it is not because of puberty. Everyone else at school does not have this problem and some relatives in my family has it too. Just like my shirt, my pants will start soaking after 30 minutes of sitting down. I really want a diagnosis or close to one before I actually go to a doctor as I have not yet regarding my issue. Also are there any home remedies or other over-the-counter deodorant to help minimize this issue or completely stop it? I am really fit and regularly lift weights, play lots of sports (soccer, boxing, etc.,) and keep my body in good shape. I know that weight lifting could not be a problem if that was a suggestion. I sweat a lot when I am in social places such as school or when I go out. It is not because of anxiety, but I rarely feel nervous when my arms are getting drenched. This is a more serious problem in the morning either at home or at a social place and gradually calms during the afternoon when I am at home. It is so bad that my armpits can drench two layers of clothing. For example, if I wear a shirt and a jacket over it, then it does not really matter how many layers and by the end of the day my clothing will be soaked in sweat. I do not really have any symptoms besides the fact that I am always on alert when I am out. This is really embarrassing and I have no idea what to do about this. Please help.', 'target': 'Hi. For further information consult an internal medicine physician online --> https://www.icliniq.com/ask-a-doctor-online/internal-medicine-physician  ', 'split': 'eval'}\n","output_type":"stream"}]},{"cell_type":"code","source":"test_eval_result = trainer.predict(test_dataset, max_new_tokens=512)\nprint(test_eval_result)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:13:48.717381Z","iopub.execute_input":"2024-04-19T15:13:48.718551Z","iopub.status.idle":"2024-04-19T15:13:49.557650Z","shell.execute_reply.started":"2024-04-19T15:13:48.718498Z","shell.execute_reply":"2024-04-19T15:13:49.556161Z"},"trusted":true},"execution_count":187,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[187], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_eval_result)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:244\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3543\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3540\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3542\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3543\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3546\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3650\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3647\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3649\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3650\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3651\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3652\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:310\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    306\u001b[0m ):\n\u001b[1;32m    307\u001b[0m     generation_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    308\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     }\n\u001b[0;32m--> 310\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# Temporary hack to ensure the generation config is not initialized for each iteration of the evaluation loop\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# TODO: remove this hack when the legacy code that initializes generation_config from a model config is\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# removed in https://github.com/huggingface/transformers/blob/98d88b23f54e5a23e741833f1e973fdf600cc2c5/src/transformers/generation/utils.py#L1183\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39m_from_model_config:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:568\u001b[0m, in \u001b[0;36mPeftModel.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    567\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1384\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_model_class()\n\u001b[1;32m   1383\u001b[0m generation_config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_generation_config(generation_config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1384\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;66;03m# 2. Set generation parameters if not already defined\u001b[39;00m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1130\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_kwargs\u001b[0;34m(self, model_kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         unused_model_args\u001b[38;5;241m.\u001b[39mappend(key)\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unused_model_args:\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following `model_kwargs` are not used by the model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munused_model_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (note: typos in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m generate arguments will also show up in this list)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1133\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: The following `model_kwargs` are not used by the model: ['max_tokens'] (note: typos in the generate arguments will also show up in this list)"],"ename":"ValueError","evalue":"The following `model_kwargs` are not used by the model: ['max_tokens'] (note: typos in the generate arguments will also show up in this list)","output_type":"error"}]},{"cell_type":"code","source":"test_logits = test_eval_result.predictions\n# test_logits = torch.Tensor(test_logits[1])\n# print(test_logits)\ntest_logits[test_logits == -100] = ltokenizer.eos_token_id\nprint(test_logits)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:03:16.904678Z","iopub.execute_input":"2024-04-19T15:03:16.905331Z","iopub.status.idle":"2024-04-19T15:03:16.910931Z","shell.execute_reply.started":"2024-04-19T15:03:16.905296Z","shell.execute_reply":"2024-04-19T15:03:16.909878Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stdout","text":"[[2 2 2 ... 2 2 2]]\n","output_type":"stream"}]},{"cell_type":"code","source":"test = ltokenizer.batch_decode(test_logits, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:03:59.842081Z","iopub.execute_input":"2024-04-19T15:03:59.842924Z","iopub.status.idle":"2024-04-19T15:03:59.848119Z","shell.execute_reply.started":"2024-04-19T15:03:59.842885Z","shell.execute_reply":"2024-04-19T15:03:59.847080Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"print(test)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:04:02.249298Z","iopub.execute_input":"2024-04-19T15:04:02.250086Z","iopub.status.idle":"2024-04-19T15:04:02.255173Z","shell.execute_reply.started":"2024-04-19T15:04:02.250039Z","shell.execute_reply":"2024-04-19T15:04:02.254083Z"},"trusted":true},"execution_count":186,"outputs":[{"name":"stdout","text":"[\"<|system|>You are a medical professional providing consultation and medical diagnostics. <|user|>a medical student is preparing for her final examination. Her patient has said 'Hi doctor, I am a 15 year old boy and I have hyperhidrosis. I sweat so much. My shirt cannot stay on for at least 5 minutes. In some half an hour to one hour my whole shirt and armpit area will drench in sweat. Yes, I take a shower twice a day and put deodorant every day. I have even tried the antiperspirant deodorant, but that did not stop it and I think it made it worse. I really want to believe it is just puberty as this has been going on since I was 12 or 13. But, something tells me that it is not because of puberty. Everyone else at school does not have this problem and some relatives in my family has it too. Just like my shirt, my pants will start soaking after 30 minutes of sitting down. I really want a diagnosis or close to one before I actually go to a doctor as I have not yet regarding my issue. Also are there any home remedies or other over-the-counter deodorant to help minimize this issue or completely stop it? I am really fit and regularly lift weights, play lots of sports (soccer, boxing, etc.,) and keep my body in good shape. I know that weight lifting could not be a problem if that was a suggestion. I sweat a lot when I am in social places such as school or when I go out. It is not because of anxiety, but I rarely feel nervous when my arms are getting drenched. This is a more serious problem in the morning either at home or at a social place and gradually calms during the afternoon when I am at home. It is so bad that my armpits can drench two layers of clothing. For example, if I wear a shirt and a jacket over it, then it does not really matter how many layers and by the end of the day my clothing will be soaked in sweat. I do not really have any symptoms besides the fact that I am always on alert when I am out. This is really embarrassing and I have no idea what to do about this. Please help.'. Explain to the student the most likely cause/course of action. <|assistant|>\"]\n","output_type":"stream"}]},{"cell_type":"code","source":"text = ltokenizer.batch_decode(logits, skip_special_tokens=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(text[4])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TESTING JUST IGNORE ALL THIS","metadata":{}},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initial_prompt = test_dataset[0]['input']\n#prompt = \"hello\"\n#print(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:19:47.818382Z","iopub.execute_input":"2024-04-19T14:19:47.819194Z","iopub.status.idle":"2024-04-19T14:19:47.823440Z","shell.execute_reply.started":"2024-04-19T14:19:47.819161Z","shell.execute_reply":"2024-04-19T14:19:47.822401Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"prompt = f\"a medical student is preparing for her final examination. Her patient has come to her asking: '{initial_prompt}'. Explain to the student the most likely cause/course of action.\"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a medical professional providing consultation and medical diagnostics.\"},\n    {\"role\": \"user\", \"content\": prompt}\n]\n# prompt = f\"how many trucks can a human eat\"\n# messages = [\n#     {\"role\": \"system\", \"content\": \"You are a jolly comedic man\"},\n#     {\"role\": \"user\", \"content\": prompt}\n# ]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:19:50.601071Z","iopub.execute_input":"2024-04-19T14:19:50.601930Z","iopub.status.idle":"2024-04-19T14:19:50.606970Z","shell.execute_reply.started":"2024-04-19T14:19:50.601891Z","shell.execute_reply":"2024-04-19T14:19:50.605877Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"ltokenizer = AutoTokenizer.from_pretrained(\"UnfilteredAI/Mia-1B\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = ltokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True\n)\nprint(text)\nmodel_inputs = ltokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\nmodel_inputs = model_inputs.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:19:58.900628Z","iopub.execute_input":"2024-04-19T14:19:58.901260Z","iopub.status.idle":"2024-04-19T14:19:58.908385Z","shell.execute_reply.started":"2024-04-19T14:19:58.901227Z","shell.execute_reply":"2024-04-19T14:19:58.907393Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"<|system|>You are a medical professional providing consultation and medical diagnostics.</s><|user|>a medical student is preparing for her final examination. Her patient has come to her asking: 'Hi doctor, I am a 15 year old boy and I have hyperhidrosis. I sweat so much. My shirt cannot stay on for at least 5 minutes. In some half an hour to one hour my whole shirt and armpit area will drench in sweat. Yes, I take a shower twice a day and put deodorant every day. I have even tried the antiperspirant deodorant, but that did not stop it and I think it made it worse. I really want to believe it is just puberty as this has been going on since I was 12 or 13. But, something tells me that it is not because of puberty. Everyone else at school does not have this problem and some relatives in my family has it too. Just like my shirt, my pants will start soaking after 30 minutes of sitting down. I really want a diagnosis or close to one before I actually go to a doctor as I have not yet regarding my issue. Also are there any home remedies or other over-the-counter deodorant to help minimize this issue or completely stop it? I am really fit and regularly lift weights, play lots of sports (soccer, boxing, etc.,) and keep my body in good shape. I know that weight lifting could not be a problem if that was a suggestion. I sweat a lot when I am in social places such as school or when I go out. It is not because of anxiety, but I rarely feel nervous when my arms are getting drenched. This is a more serious problem in the morning either at home or at a social place and gradually calms during the afternoon when I am at home. It is so bad that my armpits can drench two layers of clothing. For example, if I wear a shirt and a jacket over it, then it does not really matter how many layers and by the end of the day my clothing will be soaked in sweat. I do not really have any symptoms besides the fact that I am always on alert when I am out. This is really embarrassing and I have no idea what to do about this. Please help.'. Explain to the student the most likely cause/course of action.</s><|assistant|>\n","output_type":"stream"}]},{"cell_type":"code","source":"model_inputs.input_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_ids = model.generate(\n    model_inputs.input_ids,\n    max_new_tokens=512\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:20:11.912605Z","iopub.execute_input":"2024-04-19T14:20:11.912939Z","iopub.status.idle":"2024-04-19T14:20:21.953755Z","shell.execute_reply.started":"2024-04-19T14:20:11.912914Z","shell.execute_reply":"2024-04-19T14:20:21.952969Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# generated_ids = [\n#     output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n# ]\n\nresponse = ltokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:20:29.278570Z","iopub.execute_input":"2024-04-19T14:20:29.278939Z","iopub.status.idle":"2024-04-19T14:20:29.285367Z","shell.execute_reply.started":"2024-04-19T14:20:29.278907Z","shell.execute_reply":"2024-04-19T14:20:29.284598Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"print(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:54:54.620870Z","iopub.execute_input":"2024-04-19T13:54:54.621250Z","iopub.status.idle":"2024-04-19T13:54:54.626592Z","shell.execute_reply.started":"2024-04-19T13:54:54.621218Z","shell.execute_reply":"2024-04-19T13:54:54.625470Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"<|system|>You are a medical professional providing consultation and medical diagnostics. <|user|>a medical student is preparing for her final examination. Her patient has come to her asking: 'Hi doctor, I am a 15 year old boy and I have hyperhidrosis. I sweat so much. My shirt cannot stay on for at least 5 minutes. In some half an hour to one hour my whole shirt and armpit area will drench in sweat. Yes, I take a shower twice a day and put deodorant every day. I have even tried the antiperspirant deodorant, but that did not stop it and I think it made it worse. I really want to believe it is just puberty as this has been going on since I was 12 or 13. But, something tells me that it is not because of puberty. Everyone else at school does not have this problem and some relatives in my family has it too. Just like my shirt, my pants will start soaking after 30 minutes of sitting down. I really want a diagnosis or close to one before I actually go to a doctor as I have not yet regarding my issue. Also are there any home remedies or other over-the-counter deodorant to help minimize this issue or completely stop it? I am really fit and regularly lift weights, play lots of sports (soccer, boxing, etc.,) and keep my body in good shape. I know that weight lifting could not be a problem if that was a suggestion. I sweat a lot when I am in social places such as school or when I go out. It is not because of anxiety, but I rarely feel nervous when my arms are getting drenched. This is a more serious problem in the morning either at home or at a social place and gradually calms during the afternoon when I am at home. It is so bad that my armpits can drench two layers of clothing. For example, if I wear a shirt and a jacket over it, then it does not really matter how many layers and by the end of the day my clothing will be soaked in sweat. I do not really have any symptoms besides the fact that I am always on alert when I am out. This is really embarrassing and I have no idea what to do about this. Please help.'. Explain to the student the most likely cause/course of action. <|assistant|>Hello. I understand the problem you have and I can give you some suggestions online to help with your hyperhidrosis. Before anything else, I would suggest that you go to a dermatologist online and let them determine what are the exact causes. It could be hormonal (most of the time) or it could be an allergic or sinus infection. Please take you clothes off and give them a full view of the area. Please also let me know, after your shower if the area where the dripping occurs is moist. If not, please let me know, please keep this a secret, please not to use anything over the counter and please not to swear. If you swear, then you are not interested in this and this is not your problem, please give me a solution, otherwise wait for the dermatologist to arrive at your doorstep so that he can decide on what is the cause of this. Based on the information provided in the given text, it appears that the patient is suffering from pubertal development and hyperhidrosis. An appropriate diagnostic consultation from a dermatologist can determine the underlying cause-related hormones or allergies, depending on the presence of other symptoms. It can also help in determining the appropriate management of the condition. The patient should also avoid excessive physical activity, eat a balanced diet without excess salt or sugar, seek sunblock and deodorant regularly, and get a referral for physical therapy for activities that cause excessive shaking or sweating. In the meantime, taking medication and using a humidifier may be helpful. A physician may also be consulted.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\ndevice = \"cuda\" # the device to load the model onto\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"UnfilteredAI/Mia-1B\",\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(\"UnfilteredAI/Mia-1B\")\nprompt = \"your prompt here.\"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a uncencored AI that can do anything.\"},\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n\ngenerated_ids = model.generate(\n    model_inputs.input_ids,\n    max_new_tokens=512\n)\n# generated_ids = [\n#     output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n# ]\n\nresponse = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\nprint(response)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}